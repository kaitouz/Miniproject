{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from Data.MVTEC_data import MVTecDataloader\n",
    "from Models.STFPM import STFPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'experiment_name': 'STFPM', 'experiment_path': './Experiments/STFPM/mvtec/carpet', 'dataroot': './Datasets/mvtec/carpet', 'resume': False, 'checkpoint_save': './Experiments/STFPM/mvtec/carpet', 'checkpoint_load': './Experiments/STFPM/mvtec/carpet/best.pth.tar', 'log_path': './Experiments/STFPM/mvtec/carpet/carpet.log', 'start_epoch': 1, 'finish_epoch': 500, 'manualseed': 42, 'batchSize': 32, 'imageSize_h': 256, 'imageSize_w': 256, 'lossSize_h': 64, 'lossSize_w': 64, 'device': 'gpu', 'gpu_ids': 0, 'ngpu': 1, 'lr': 0.4, 'momentum': 0.9, 'weight_decay': 0.0001, 'sample_interval': 20}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = OmegaConf.load('./Config/mvtec_STFPM_config.yaml')\n",
    "os.makedirs(args.experiment_path, exist_ok=True)\n",
    "os.makedirs(args.checkpoint_save, exist_ok=True)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader = MVTecDataloader(args.dataroot, batchSize=args.batchSize, imageSize_h=args.imageSize_h, imageSize_w=args.imageSize_w, is_train=True)\n",
    "test_neg_loader, test_pos_loader = MVTecDataloader(args.dataroot, batchSize=args.batchSize, imageSize_h=args.imageSize_h, imageSize_w=args.imageSize_w, is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gin/miniconda3/envs/vdt/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/gin/miniconda3/envs/vdt/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint load fail.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gin/miniconda3/envs/vdt/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "Trainer = STFPM(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a16fc4d078d7408daf0d001a0d2d402a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/500] loss: 3.018981\n",
      "Valid Loss: 2.0120394\n",
      "AUC =  0.48836276083467095\n",
      "Checkpoint saved successfully at epoch 1\n",
      "[2/500] loss: 1.640610\n",
      "Valid Loss: 2.1175640\n",
      "AUC =  0.6577046548956661\n",
      "Checkpoint saved successfully at epoch 2\n",
      "[3/500] loss: 0.953990\n",
      "Valid Loss: 0.6976763\n",
      "AUC =  0.4791332263242376\n",
      "[4/500] loss: 0.740139\n",
      "Valid Loss: 0.0267853\n",
      "AUC =  0.8836276083467095\n",
      "Checkpoint saved successfully at epoch 4\n",
      "[5/500] loss: 0.645670\n",
      "Valid Loss: 0.0128897\n",
      "AUC =  0.9478330658105939\n",
      "Checkpoint saved successfully at epoch 5\n",
      "[6/500] loss: 0.587208\n",
      "Valid Loss: 0.0087758\n",
      "AUC =  0.9622792937399679\n",
      "Checkpoint saved successfully at epoch 6\n",
      "[7/500] loss: 0.547799\n",
      "Valid Loss: 0.0055536\n",
      "AUC =  0.9775280898876404\n",
      "Checkpoint saved successfully at epoch 7\n",
      "[8/500] loss: 0.521615\n",
      "Valid Loss: 0.0062946\n",
      "AUC =  0.9153290529695024\n",
      "[9/500] loss: 0.499048\n",
      "Valid Loss: 0.0057467\n",
      "AUC =  0.8940609951845907\n",
      "[10/500] loss: 0.483732\n",
      "Valid Loss: 0.0037382\n",
      "AUC =  0.949438202247191\n",
      "[11/500] loss: 0.467652\n",
      "Valid Loss: 0.0037068\n",
      "AUC =  0.92776886035313\n",
      "[12/500] loss: 0.455566\n",
      "Valid Loss: 0.0033077\n",
      "AUC =  0.9301765650080257\n",
      "[13/500] loss: 0.444679\n",
      "Valid Loss: 0.0034195\n",
      "AUC =  0.9012841091492777\n",
      "[14/500] loss: 0.435171\n",
      "Valid Loss: 0.0043200\n",
      "AUC =  0.8105939004815409\n",
      "[15/500] loss: 0.427137\n",
      "Valid Loss: 0.0031365\n",
      "AUC =  0.8735955056179775\n",
      "[16/500] loss: 0.419622\n",
      "Valid Loss: 0.0022749\n",
      "AUC =  0.9831460674157304\n",
      "Checkpoint saved successfully at epoch 16\n",
      "[17/500] loss: 0.409907\n",
      "Valid Loss: 0.0022208\n",
      "AUC =  0.9715088282504012\n",
      "[18/500] loss: 0.404600\n",
      "Valid Loss: 0.0141520\n",
      "AUC =  0.5898876404494382\n",
      "[19/500] loss: 0.396773\n",
      "Valid Loss: 0.0021288\n",
      "AUC =  0.9486356340288924\n",
      "[20/500] loss: 0.389213\n",
      "Valid Loss: 0.0019899\n",
      "AUC =  0.9125200642054575\n",
      "[21/500] loss: 0.382590\n",
      "Valid Loss: 0.0020433\n",
      "AUC =  0.8711878009630818\n",
      "[22/500] loss: 0.376010\n",
      "Valid Loss: 0.0017800\n",
      "AUC =  0.9398073836276083\n",
      "[23/500] loss: 0.369191\n",
      "Valid Loss: 0.0016695\n",
      "AUC =  0.9365971107544141\n",
      "[24/500] loss: 0.363406\n",
      "Valid Loss: 0.0016120\n",
      "AUC =  0.9225521669341894\n",
      "[25/500] loss: 0.357914\n",
      "Valid Loss: 0.0016106\n",
      "AUC =  0.9052969502407704\n",
      "[26/500] loss: 0.352806\n",
      "Valid Loss: 0.0014469\n",
      "AUC =  0.9161316211878009\n",
      "[27/500] loss: 0.347502\n",
      "Valid Loss: 0.0014881\n",
      "AUC =  0.858346709470305\n",
      "[28/500] loss: 0.342898\n",
      "Valid Loss: 0.0015278\n",
      "AUC =  0.7917335473515248\n",
      "[29/500] loss: 0.343490\n",
      "Valid Loss: 0.0336767\n",
      "AUC =  0.3198234349919743\n",
      "[30/500] loss: 0.349192\n",
      "Valid Loss: 0.0053766\n",
      "AUC =  0.5248796147672552\n",
      "[31/500] loss: 0.338327\n",
      "Valid Loss: 0.0014408\n",
      "AUC =  0.8892455858747994\n",
      "[32/500] loss: 0.330088\n",
      "Valid Loss: 0.0014439\n",
      "AUC =  0.8908507223113965\n",
      "[33/500] loss: 0.323785\n",
      "Valid Loss: 0.0011962\n",
      "AUC =  0.9446227929373997\n",
      "[34/500] loss: 0.318293\n",
      "Valid Loss: 0.0010262\n",
      "AUC =  0.959470304975923\n",
      "[35/500] loss: 0.313691\n",
      "Valid Loss: 0.0009755\n",
      "AUC =  0.9542536115569823\n",
      "[36/500] loss: 0.309240\n",
      "Valid Loss: 0.0009609\n",
      "AUC =  0.9329855537720706\n",
      "[37/500] loss: 0.304502\n",
      "Valid Loss: 0.0009605\n",
      "AUC =  0.9121187800963082\n",
      "[38/500] loss: 0.300487\n",
      "Valid Loss: 0.0009472\n",
      "AUC =  0.9048956661316212\n",
      "[39/500] loss: 0.296907\n",
      "Valid Loss: 0.0009163\n",
      "AUC =  0.9081059390048154\n",
      "[40/500] loss: 0.293523\n",
      "Valid Loss: 0.0008891\n",
      "AUC =  0.9056982343499198\n",
      "[41/500] loss: 0.290225\n",
      "Valid Loss: 0.0008527\n",
      "AUC =  0.9048956661316212\n",
      "[42/500] loss: 0.287018\n",
      "Valid Loss: 0.0008280\n",
      "AUC =  0.8972712680577849\n",
      "[43/500] loss: 0.283896\n",
      "Valid Loss: 0.0008169\n",
      "AUC =  0.8792134831460674\n",
      "[44/500] loss: 0.280843\n",
      "Valid Loss: 0.0007995\n",
      "AUC =  0.8611556982343499\n",
      "[45/500] loss: 0.277781\n",
      "Valid Loss: 0.0008154\n",
      "AUC =  0.8218298555377207\n",
      "[46/500] loss: 0.274974\n",
      "Valid Loss: 0.0007707\n",
      "AUC =  0.833868378812199\n",
      "[47/500] loss: 0.272245\n",
      "Valid Loss: 0.0008531\n",
      "AUC =  0.7479935794542536\n",
      "[48/500] loss: 0.269886\n",
      "Valid Loss: 0.0007359\n",
      "AUC =  0.8186195826645264\n",
      "[49/500] loss: 0.269395\n",
      "Valid Loss: 0.0118871\n",
      "AUC =  0.3968699839486356\n",
      "[50/500] loss: 0.270952\n",
      "Valid Loss: 0.0082965\n",
      "AUC =  0.5012038523274478\n",
      "Checkpoint saved successfully at epoch 50\n",
      "[51/500] loss: 0.270596\n",
      "Valid Loss: 0.0011426\n",
      "AUC =  0.7885232744783306\n",
      "[52/500] loss: 0.265484\n",
      "Valid Loss: 0.0006495\n",
      "AUC =  0.9646869983948635\n",
      "[53/500] loss: 0.261413\n",
      "Valid Loss: 0.0006201\n",
      "AUC =  0.9161316211878009\n",
      "[54/500] loss: 0.257182\n",
      "Valid Loss: 0.0005938\n",
      "AUC =  0.9145264847512038\n",
      "[55/500] loss: 0.253712\n",
      "Valid Loss: 0.0005641\n",
      "AUC =  0.8964686998394864\n",
      "[56/500] loss: 0.250587\n",
      "Valid Loss: 0.0005630\n",
      "AUC =  0.9097110754414125\n",
      "[57/500] loss: 0.247626\n",
      "Valid Loss: 0.0005471\n",
      "AUC =  0.9081059390048154\n",
      "[58/500] loss: 0.245041\n",
      "Valid Loss: 0.0005519\n",
      "AUC =  0.8747993579454253\n",
      "[59/500] loss: 0.242667\n",
      "Valid Loss: 0.0005519\n",
      "AUC =  0.8475120385232744\n",
      "[60/500] loss: 0.240486\n",
      "Valid Loss: 0.0005622\n",
      "AUC =  0.8202247191011236\n",
      "[61/500] loss: 0.238523\n",
      "Valid Loss: 0.0005596\n",
      "AUC =  0.8170144462279294\n",
      "[62/500] loss: 0.236806\n",
      "Valid Loss: 0.0005669\n",
      "AUC =  0.8258426966292134\n",
      "[63/500] loss: 0.235371\n",
      "Valid Loss: 0.0006046\n",
      "AUC =  0.8085874799357945\n",
      "[64/500] loss: 0.234513\n",
      "Valid Loss: 0.0050088\n",
      "AUC =  0.4430176565008026\n",
      "[65/500] loss: 0.236741\n",
      "Valid Loss: 0.0053741\n",
      "AUC =  0.41813804173354735\n",
      "[66/500] loss: 0.234740\n",
      "Valid Loss: 0.0005814\n",
      "AUC =  0.8126003210272873\n",
      "[67/500] loss: 0.231162\n",
      "Valid Loss: 0.0004150\n",
      "AUC =  0.9803370786516853\n",
      "[68/500] loss: 0.228645\n",
      "Valid Loss: 0.0004324\n",
      "AUC =  0.9052969502407705\n",
      "[69/500] loss: 0.227606\n",
      "Valid Loss: 0.0003837\n",
      "AUC =  0.9823434991974317\n",
      "[70/500] loss: 0.224567\n",
      "Valid Loss: 0.0005146\n",
      "AUC =  0.8643659711075442\n",
      "[71/500] loss: 0.222161\n",
      "Valid Loss: 0.0004106\n",
      "AUC =  0.9514446227929374\n",
      "[72/500] loss: 0.220177\n",
      "Valid Loss: 0.0003441\n",
      "AUC =  0.9735152487961476\n",
      "[73/500] loss: 0.218246\n",
      "Valid Loss: 0.0005584\n",
      "AUC =  0.7178972712680578\n",
      "[74/500] loss: 0.216299\n",
      "Valid Loss: 0.0003869\n",
      "AUC =  0.8619582664526485\n",
      "[75/500] loss: 0.214451\n",
      "Valid Loss: 0.0003429\n",
      "AUC =  0.9225521669341894\n",
      "[76/500] loss: 0.212785\n",
      "Valid Loss: 0.0003442\n",
      "AUC =  0.9093097913322632\n",
      "[77/500] loss: 0.211281\n",
      "Valid Loss: 0.0003482\n",
      "AUC =  0.8936597110754414\n",
      "[78/500] loss: 0.209837\n",
      "Valid Loss: 0.0003523\n",
      "AUC =  0.880016051364366\n",
      "[79/500] loss: 0.208427\n",
      "Valid Loss: 0.0003529\n",
      "AUC =  0.8719903691813804\n",
      "[80/500] loss: 0.207040\n",
      "Valid Loss: 0.0003509\n",
      "AUC =  0.8655698234349919\n",
      "[81/500] loss: 0.205668\n",
      "Valid Loss: 0.0003487\n",
      "AUC =  0.862760834670947\n",
      "[82/500] loss: 0.204323\n",
      "Valid Loss: 0.0003471\n",
      "AUC =  0.8583467094703049\n",
      "[83/500] loss: 0.202999\n",
      "Valid Loss: 0.0003475\n",
      "AUC =  0.8511235955056179\n",
      "[84/500] loss: 0.201699\n",
      "Valid Loss: 0.0003488\n",
      "AUC =  0.8378812199036918\n",
      "[85/500] loss: 0.200423\n",
      "Valid Loss: 0.0003460\n",
      "AUC =  0.8346709470304976\n",
      "[86/500] loss: 0.199170\n",
      "Valid Loss: 0.0003518\n",
      "AUC =  0.8238362760834671\n",
      "[87/500] loss: 0.197957\n",
      "Valid Loss: 0.0003634\n",
      "AUC =  0.7985553772070626\n",
      "[88/500] loss: 0.196904\n",
      "Valid Loss: 0.0003667\n",
      "AUC =  0.7768860353130016\n",
      "[89/500] loss: 0.196932\n",
      "Valid Loss: 0.0172594\n",
      "AUC =  0.38924558587479935\n",
      "[90/500] loss: 0.202099\n",
      "Valid Loss: 0.0262749\n",
      "AUC =  0.8683788121990369\n",
      "[91/500] loss: 0.225300\n",
      "Valid Loss: 0.2532111\n",
      "AUC =  0.40730337078651685\n",
      "[92/500] loss: 0.217587\n",
      "Valid Loss: 0.0102422\n",
      "AUC =  0.41011235955056174\n",
      "[93/500] loss: 0.205116\n",
      "Valid Loss: 0.0005231\n",
      "AUC =  0.8382825040128411\n",
      "[94/500] loss: 0.198608\n",
      "Valid Loss: 0.0004237\n",
      "AUC =  0.8274478330658106\n",
      "[95/500] loss: 0.194980\n",
      "Valid Loss: 0.0002806\n",
      "AUC =  0.9751203852327447\n",
      "[96/500] loss: 0.193490\n",
      "Valid Loss: 0.0005016\n",
      "AUC =  0.7696629213483146\n",
      "[97/500] loss: 0.192902\n",
      "Valid Loss: 0.0002284\n",
      "AUC =  0.978330658105939\n",
      "[98/500] loss: 0.189890\n",
      "Valid Loss: 0.0002674\n",
      "AUC =  0.9843499197431782\n",
      "Checkpoint saved successfully at epoch 98\n",
      "[99/500] loss: 0.187671\n",
      "Valid Loss: 0.0002284\n",
      "AUC =  0.9787319422150883\n",
      "[100/500] loss: 0.185748\n",
      "Valid Loss: 0.0002141\n",
      "AUC =  0.9787319422150883\n",
      "Checkpoint saved successfully at epoch 100\n",
      "[101/500] loss: 0.184085\n",
      "Valid Loss: 0.0002140\n",
      "AUC =  0.9759229534510433\n",
      "[102/500] loss: 0.182683\n",
      "Valid Loss: 0.0002382\n",
      "AUC =  0.9498394863563403\n",
      "[103/500] loss: 0.181446\n",
      "Valid Loss: 0.0002530\n",
      "AUC =  0.9153290529695025\n",
      "[104/500] loss: 0.180314\n",
      "Valid Loss: 0.0002602\n",
      "AUC =  0.9004815409309792\n",
      "[105/500] loss: 0.179264\n",
      "Valid Loss: 0.0002541\n",
      "AUC =  0.9052969502407704\n",
      "[106/500] loss: 0.178247\n",
      "Valid Loss: 0.0002439\n",
      "AUC =  0.9149277688603531\n",
      "[107/500] loss: 0.177246\n",
      "Valid Loss: 0.0002292\n",
      "AUC =  0.9398073836276083\n",
      "[108/500] loss: 0.176237\n",
      "Valid Loss: 0.0002149\n",
      "AUC =  0.9606741573033707\n",
      "[109/500] loss: 0.175228\n",
      "Valid Loss: 0.0002061\n",
      "AUC =  0.9674959871589085\n",
      "[110/500] loss: 0.174232\n",
      "Valid Loss: 0.0002039\n",
      "AUC =  0.9686998394863563\n",
      "[111/500] loss: 0.173258\n",
      "Valid Loss: 0.0002066\n",
      "AUC =  0.9610754414125201\n",
      "[112/500] loss: 0.172284\n",
      "Valid Loss: 0.0002108\n",
      "AUC =  0.9526484751203852\n",
      "[113/500] loss: 0.171318\n",
      "Valid Loss: 0.0002144\n",
      "AUC =  0.942215088282504\n",
      "[114/500] loss: 0.170388\n",
      "Valid Loss: 0.0002200\n",
      "AUC =  0.9309791332263242\n",
      "[115/500] loss: 0.169509\n",
      "Valid Loss: 0.0002275\n",
      "AUC =  0.9113162118780096\n",
      "[116/500] loss: 0.168650\n",
      "Valid Loss: 0.0002366\n",
      "AUC =  0.8900481540930979\n",
      "[117/500] loss: 0.167821\n",
      "Valid Loss: 0.0002440\n",
      "AUC =  0.8756019261637238\n",
      "[118/500] loss: 0.167020\n",
      "Valid Loss: 0.0002491\n",
      "AUC =  0.8603531300160514\n",
      "[119/500] loss: 0.166364\n",
      "Valid Loss: 0.0002541\n",
      "AUC =  0.8515248796147672\n",
      "[120/500] loss: 0.165626\n",
      "Valid Loss: 0.0002794\n",
      "AUC =  0.8346709470304976\n",
      "[121/500] loss: 0.164880\n",
      "Valid Loss: 0.0003677\n",
      "AUC =  0.7937399678972712\n",
      "[122/500] loss: 0.164381\n",
      "Valid Loss: 0.0006679\n",
      "AUC =  0.7307383627608347\n",
      "[123/500] loss: 0.163922\n",
      "Valid Loss: 0.0002551\n",
      "AUC =  0.8503210272873195\n",
      "[124/500] loss: 0.163212\n",
      "Valid Loss: 0.0581295\n",
      "AUC =  0.7323434991974319\n",
      "[125/500] loss: 0.166219\n",
      "Valid Loss: 0.3698859\n",
      "AUC =  0.8013643659711076\n",
      "[126/500] loss: 0.347564\n",
      "Valid Loss: 0.3205533\n",
      "AUC =  0.7030497592295344\n",
      "[127/500] loss: 0.336891\n",
      "Valid Loss: 0.1606953\n",
      "AUC =  0.4971910112359551\n",
      "[128/500] loss: 0.277594\n",
      "Valid Loss: 0.0056521\n",
      "AUC =  0.5449438202247191\n",
      "[129/500] loss: 0.243575\n",
      "Valid Loss: 0.0011800\n",
      "AUC =  0.8206260032102728\n",
      "[130/500] loss: 0.225312\n",
      "Valid Loss: 0.0007650\n",
      "AUC =  0.9229534510433386\n",
      "[131/500] loss: 0.213024\n",
      "Valid Loss: 0.0005640\n",
      "AUC =  0.9410112359550562\n",
      "[132/500] loss: 0.205276\n",
      "Valid Loss: 0.0004483\n",
      "AUC =  0.9169341894060995\n",
      "[133/500] loss: 0.199929\n",
      "Valid Loss: 0.0004036\n",
      "AUC =  0.9177367576243981\n",
      "[134/500] loss: 0.195978\n",
      "Valid Loss: 0.0004205\n",
      "AUC =  0.9004815409309791\n",
      "[135/500] loss: 0.192904\n",
      "Valid Loss: 0.0003473\n",
      "AUC =  0.9069020866773676\n",
      "[136/500] loss: 0.190018\n",
      "Valid Loss: 0.0003444\n",
      "AUC =  0.9093097913322633\n",
      "[137/500] loss: 0.188129\n",
      "Valid Loss: 0.0003893\n",
      "AUC =  0.8547351524879614\n",
      "[138/500] loss: 0.186427\n",
      "Valid Loss: 0.0002948\n",
      "AUC =  0.8956661316211878\n",
      "[139/500] loss: 0.182105\n",
      "Valid Loss: 0.0002342\n",
      "AUC =  0.9189406099518458\n",
      "[140/500] loss: 0.179061\n",
      "Valid Loss: 0.0002075\n",
      "AUC =  0.9373996789727126\n",
      "[141/500] loss: 0.176646\n",
      "Valid Loss: 0.0002125\n",
      "AUC =  0.9289727126805778\n",
      "[142/500] loss: 0.174644\n",
      "Valid Loss: 0.0002122\n",
      "AUC =  0.9309791332263242\n",
      "[143/500] loss: 0.172895\n",
      "Valid Loss: 0.0001984\n",
      "AUC =  0.9390048154093098\n",
      "[144/500] loss: 0.171442\n",
      "Valid Loss: 0.0001891\n",
      "AUC =  0.9418138041733547\n",
      "[145/500] loss: 0.170175\n",
      "Valid Loss: 0.0001845\n",
      "AUC =  0.9382022471910112\n",
      "[146/500] loss: 0.169047\n",
      "Valid Loss: 0.0001835\n",
      "AUC =  0.9313804173354735\n",
      "[147/500] loss: 0.167988\n",
      "Valid Loss: 0.0001825\n",
      "AUC =  0.9241573033707865\n",
      "[148/500] loss: 0.167007\n",
      "Valid Loss: 0.0001818\n",
      "AUC =  0.9081059390048154\n",
      "[149/500] loss: 0.166219\n",
      "Valid Loss: 0.0001720\n",
      "AUC =  0.9185393258426966\n",
      "[150/500] loss: 0.165350\n",
      "Valid Loss: 0.0001605\n",
      "AUC =  0.9181380417335474\n",
      "Checkpoint saved successfully at epoch 150\n",
      "[151/500] loss: 0.164485\n",
      "Valid Loss: 0.0001639\n",
      "AUC =  0.906099518459069\n",
      "[152/500] loss: 0.163959\n",
      "Valid Loss: 0.0001604\n",
      "AUC =  0.9201444622792938\n",
      "[153/500] loss: 0.164009\n",
      "Valid Loss: 0.0001439\n",
      "AUC =  0.9699036918138042\n",
      "[154/500] loss: 0.167665\n",
      "Valid Loss: 0.0002137\n",
      "AUC =  0.973916532905297\n",
      "[155/500] loss: 0.174049\n",
      "Valid Loss: 0.0019341\n",
      "AUC =  0.49518459069020865\n",
      "[156/500] loss: 0.171165\n",
      "Valid Loss: 0.0002099\n",
      "AUC =  0.9506420545746388\n",
      "[157/500] loss: 0.164832\n",
      "Valid Loss: 0.0001585\n",
      "AUC =  0.9719101123595505\n",
      "[158/500] loss: 0.161362\n",
      "Valid Loss: 0.0001417\n",
      "AUC =  0.9534510433386838\n",
      "[159/500] loss: 0.159614\n",
      "Valid Loss: 0.0001294\n",
      "AUC =  0.963884430176565\n",
      "[160/500] loss: 0.158063\n",
      "Valid Loss: 0.0001282\n",
      "AUC =  0.9514446227929374\n",
      "[161/500] loss: 0.156877\n",
      "Valid Loss: 0.0001280\n",
      "AUC =  0.9325842696629213\n",
      "[162/500] loss: 0.155914\n",
      "Valid Loss: 0.0001283\n",
      "AUC =  0.9197431781701444\n",
      "[163/500] loss: 0.155053\n",
      "Valid Loss: 0.0001268\n",
      "AUC =  0.9169341894060995\n",
      "[164/500] loss: 0.154249\n",
      "Valid Loss: 0.0001256\n",
      "AUC =  0.9181380417335473\n",
      "[165/500] loss: 0.153435\n",
      "Valid Loss: 0.0001248\n",
      "AUC =  0.9229534510433387\n",
      "[166/500] loss: 0.152643\n",
      "Valid Loss: 0.0001225\n",
      "AUC =  0.9293739967897272\n",
      "[167/500] loss: 0.151849\n",
      "Valid Loss: 0.0001203\n",
      "AUC =  0.9337881219903692\n",
      "[168/500] loss: 0.151066\n",
      "Valid Loss: 0.0001188\n",
      "AUC =  0.9341894060995185\n",
      "[169/500] loss: 0.150266\n",
      "Valid Loss: 0.0001180\n",
      "AUC =  0.9337881219903692\n",
      "[170/500] loss: 0.149597\n",
      "Valid Loss: 0.0001169\n",
      "AUC =  0.9337881219903692\n",
      "[171/500] loss: 0.149142\n",
      "Valid Loss: 0.0001138\n",
      "AUC =  0.9373996789727127\n",
      "[172/500] loss: 0.149605\n",
      "Valid Loss: 0.0001523\n",
      "AUC =  0.8984751203852328\n",
      "[173/500] loss: 0.149255\n",
      "Valid Loss: 0.0001327\n",
      "AUC =  0.8924558587479936\n",
      "[174/500] loss: 0.148309\n",
      "Valid Loss: 0.0001266\n",
      "AUC =  0.9137239165329053\n",
      "[175/500] loss: 0.147346\n",
      "Valid Loss: 0.0001267\n",
      "AUC =  0.9261637239165329\n",
      "[176/500] loss: 0.146441\n",
      "Valid Loss: 0.0001198\n",
      "AUC =  0.9418138041733548\n",
      "[177/500] loss: 0.145905\n",
      "Valid Loss: 0.0001224\n",
      "AUC =  0.949438202247191\n",
      "[178/500] loss: 0.145772\n",
      "Valid Loss: 0.0001206\n",
      "AUC =  0.9329855537720706\n",
      "[179/500] loss: 0.145625\n",
      "Valid Loss: 0.0001207\n",
      "AUC =  0.9004815409309791\n",
      "[180/500] loss: 0.147686\n",
      "Valid Loss: 0.0001278\n",
      "AUC =  0.9835473515248796\n",
      "[181/500] loss: 0.145238\n",
      "Valid Loss: 0.0001499\n",
      "AUC =  0.884430176565008\n",
      "[182/500] loss: 0.143455\n",
      "Valid Loss: 0.0001324\n",
      "AUC =  0.891653290529695\n",
      "[183/500] loss: 0.142111\n",
      "Valid Loss: 0.0001279\n",
      "AUC =  0.9325842696629213\n",
      "[184/500] loss: 0.140987\n",
      "Valid Loss: 0.0001252\n",
      "AUC =  0.9470304975922954\n",
      "[185/500] loss: 0.140068\n",
      "Valid Loss: 0.0001314\n",
      "AUC =  0.9382022471910112\n",
      "[186/500] loss: 0.139265\n",
      "Valid Loss: 0.0001258\n",
      "AUC =  0.9313804173354736\n",
      "[187/500] loss: 0.138504\n",
      "Valid Loss: 0.0001093\n",
      "AUC =  0.9281701444622794\n",
      "[188/500] loss: 0.137737\n",
      "Valid Loss: 0.0000989\n",
      "AUC =  0.9309791332263243\n",
      "[189/500] loss: 0.136951\n",
      "Valid Loss: 0.0000938\n",
      "AUC =  0.9345906902086678\n",
      "[190/500] loss: 0.136037\n",
      "Valid Loss: 0.0000938\n",
      "AUC =  0.9365971107544142\n",
      "[191/500] loss: 0.135163\n",
      "Valid Loss: 0.0000961\n",
      "AUC =  0.9386035313001604\n",
      "[192/500] loss: 0.134393\n",
      "Valid Loss: 0.0000970\n",
      "AUC =  0.934991974317817\n",
      "[193/500] loss: 0.133704\n",
      "Valid Loss: 0.0000959\n",
      "AUC =  0.9390048154093098\n",
      "[194/500] loss: 0.133087\n",
      "Valid Loss: 0.0000926\n",
      "AUC =  0.9462279293739968\n",
      "[195/500] loss: 0.132432\n",
      "Valid Loss: 0.0000855\n",
      "AUC =  0.9482343499197431\n",
      "[196/500] loss: 0.131795\n",
      "Valid Loss: 0.0000829\n",
      "AUC =  0.9454253611556982\n",
      "[197/500] loss: 0.131178\n",
      "Valid Loss: 0.0000846\n",
      "AUC =  0.9402086677367576\n",
      "[198/500] loss: 0.130664\n",
      "Valid Loss: 0.0000864\n",
      "AUC =  0.9454253611556982\n",
      "[199/500] loss: 0.130122\n",
      "Valid Loss: 0.0000845\n",
      "AUC =  0.9450240770465489\n",
      "[200/500] loss: 0.129699\n",
      "Valid Loss: 0.0000831\n",
      "AUC =  0.9353932584269664\n",
      "Checkpoint saved successfully at epoch 200\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m Trainer\u001b[39m.\u001b[39;49mtrain(train_loader, val_loader, test_neg_loader, test_pos_loader)\n",
      "File \u001b[0;32m~/Desktop/FINAL_PROJECT/Models/STFPM/__init__.py:103\u001b[0m, in \u001b[0;36mSTFPM.train\u001b[0;34m(self, train_loader, val_loader, test_neg_loader, test_pos_loader)\u001b[0m\n\u001b[1;32m    100\u001b[0m imgs \u001b[39m=\u001b[39m imgs\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m    102\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 103\u001b[0m     teacher_feat \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mteacher(imgs)\n\u001b[1;32m    104\u001b[0m student_feat \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstudent(imgs)\n\u001b[1;32m    106\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/vdt/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/FINAL_PROJECT/Models/STFPM/__init__.py:25\u001b[0m, in \u001b[0;36mResNet18_MS3.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     23\u001b[0m res \u001b[39m=\u001b[39m []\n\u001b[1;32m     24\u001b[0m \u001b[39mfor\u001b[39;00m name, module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39m_modules\u001b[39m.\u001b[39mitems():\n\u001b[0;32m---> 25\u001b[0m     x \u001b[39m=\u001b[39m module(x)\n\u001b[1;32m     26\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39m4\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m5\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m6\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[1;32m     27\u001b[0m         res\u001b[39m.\u001b[39mappend(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/vdt/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/vdt/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/vdt/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/vdt/lib/python3.10/site-packages/torchvision/models/resnet.py:92\u001b[0m, in \u001b[0;36mBasicBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m     90\u001b[0m     identity \u001b[39m=\u001b[39m x\n\u001b[0;32m---> 92\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1(x)\n\u001b[1;32m     93\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn1(out)\n\u001b[1;32m     94\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(out)\n",
      "File \u001b[0;32m~/miniconda3/envs/vdt/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/vdt/lib/python3.10/site-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/miniconda3/envs/vdt/lib/python3.10/site-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    460\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Trainer.train(train_loader, val_loader, test_neg_loader, test_pos_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = Trainer.test(test_pos_loader)\n",
    "neg = Trainer.test(test_neg_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.14376194e-02, 1.17080384e-02, 2.82905775e-03, 9.41141951e-03,\n",
       "       3.29814935e-02, 6.25306356e-03, 2.10062583e-03, 1.91917494e-02,\n",
       "       1.14655469e-01, 1.32854409e-02, 1.75816030e-02, 1.00623179e-01,\n",
       "       6.63937312e-02, 7.22838156e-02, 1.10096682e-02, 3.06252986e-02,\n",
       "       1.44852810e-02, 3.42285377e-03, 2.01595151e-02, 1.50847193e-01,\n",
       "       3.67848640e-02, 4.35731979e-02, 6.29456528e-02, 1.80646563e-02,\n",
       "       4.57492843e-02, 4.80912197e-02, 4.11236389e-02, 1.04348490e-02,\n",
       "       5.00516947e-02, 2.23178156e-02, 6.98211454e-02, 1.05834045e-01,\n",
       "       3.95228053e-02, 5.49225062e-02, 1.06132871e-01, 2.67208717e-02,\n",
       "       3.00291036e-02, 6.41739718e-03, 1.84559647e-02, 2.61985511e-02,\n",
       "       5.45366565e-02, 3.09775663e-02, 8.14575851e-02, 8.31486592e-02,\n",
       "       1.48470655e-01, 5.84914684e-02, 5.61299575e-02, 6.32488253e-02,\n",
       "       2.21372531e-02, 6.39471905e-02, 1.15872885e-01, 4.42887489e-02,\n",
       "       2.35751639e-02, 6.58478471e-03, 5.40282566e-03, 2.14304086e-02,\n",
       "       3.77323246e-02, 4.88153165e-02, 1.47400834e-01, 8.72888854e-02,\n",
       "       4.92152506e-02, 5.38626863e-02, 3.03852446e-02, 9.77397896e-02,\n",
       "       2.52180840e-02, 4.58635315e-02, 1.09475749e-01, 2.79731876e-02,\n",
       "       3.17659914e-02, 6.64917268e-02, 4.55207014e-02, 1.35619920e-02,\n",
       "       4.42143977e-02, 1.65621184e-02, 4.06163745e-02, 9.89691932e-02,\n",
       "       3.57755520e-02, 3.41736833e-02, 6.86069906e-01, 1.83088024e-03,\n",
       "       2.27269209e-02, 6.77533774e-03, 9.92549807e-02, 1.56286124e-01,\n",
       "       1.67065407e-02, 1.81164299e-03, 1.63526041e-02, 1.03542643e-01,\n",
       "       2.20869601e-03, 8.71742035e-04, 1.11252035e-03, 9.20235805e-04,\n",
       "       1.23150437e-03, 1.87657715e-03, 1.10373591e-03, 2.88562058e-03,\n",
       "       1.06825329e-03, 7.17024021e-02, 2.09592155e-03, 9.44850879e-04,\n",
       "       1.39127485e-03, 1.85491896e-03, 1.21664854e-03, 4.48750285e-02,\n",
       "       1.34204789e-03, 1.70214224e-03, 6.11748721e-04, 1.40293012e-03,\n",
       "       7.16693699e-03, 3.04578879e-03, 1.01261819e-03, 4.88120923e-03,\n",
       "       1.53814733e-03, 1.92801832e-03, 1.54640240e-03, 1.54127623e-03,\n",
       "       2.80305138e-03])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = []\n",
    "for i in range(len(pos)):\n",
    "    temp = cv2.resize(pos[i], (128, 192))\n",
    "    scores.append(temp)\n",
    "for i in range(len(neg)):\n",
    "    temp = cv2.resize(neg[i], (128, 192))\n",
    "    scores.append(temp)\n",
    "\n",
    "scores = np.stack(scores)\n",
    "gt_image = np.concatenate((np.ones(pos.shape[0], dtype=np.bool_), np.zeros(neg.shape[0], dtype=np.bool_)), 0)        \n",
    "\n",
    "# auc_image_max = evaluate(gt_image, scores.max(-1).max(-1), metric='roc')\n",
    "scores.max(-1).max(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9361958266452649"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(gt_image, scores.max(-1).max(-1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vdt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
